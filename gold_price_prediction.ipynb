{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Intrusion Detection System (NIDS) using Self-Taught Learning\n",
    "## Implementation with NSL-KDD Dataset\n",
    "\n",
    "### Objectives:\n",
    "1. Implement 3 classification scenarios:\n",
    "   - Binary Classification (Normal vs Anomaly)\n",
    "   - 5-Class Classification (Normal + 4 Attack Categories)\n",
    "   - 23-Class Classification (Normal + 22 Attacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load NSL-KDD Dataset\n",
    "def load_nsl_kdd_data(path='NSL-KDD/KDDTrain+.txt', test_path='NSL-KDD/KDDTest+.txt'):\n",
    "    # Column names for NSL-KDD dataset\n",
    "    columns = [\n",
    "        'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', \n",
    "        'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', \n",
    "        'logged_in', 'num_compromised', 'root_shell', 'su_attempted', \n",
    "        'num_root', 'num_file_creations', 'num_shells', 'num_access_files', \n",
    "        'num_outbound_cmds', 'is_host_login', 'is_guest_login', 'count', \n",
    "        'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', \n",
    "        'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', \n",
    "        'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', \n",
    "        'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', \n",
    "        'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', \n",
    "        'dst_host_srv_serror_rate', 'dst_host_rerror_rate', \n",
    "        'dst_host_srv_rerror_rate', 'attack_type', 'difficulty_level'\n",
    "    ]\n",
    "    \n",
    "    # Load training and test data\n",
    "    train_data = pd.read_csv(path, header=None, names=columns)\n",
    "    test_data = pd.read_csv(test_path, header=None, names=columns)\n",
    "    \n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Preprocessing Function\n",
    "def preprocess_data(train_data, test_data, classification_type='binary'):\n",
    "    # Encode categorical features\n",
    "    categorical_columns = ['protocol_type', 'service', 'flag']\n",
    "    for col in categorical_columns:\n",
    "        le = LabelEncoder()\n",
    "        train_data[col] = le.fit_transform(train_data[col])\n",
    "        test_data[col] = le.transform(test_data[col])\n",
    "    \n",
    "    # Create attack classification labels\n",
    "    if classification_type == 'binary':\n",
    "        train_data['label'] = (train_data['attack_type'] != 'normal').astype(int)\n",
    "        test_data['label'] = (test_data['attack_type'] != 'normal').astype(int)\n",
    "    elif classification_type == '5class':\n",
    "        # Map to 5 attack categories\n",
    "        attack_map = {\n",
    "            'normal': 0,\n",
    "            'DoS': 1,\n",
    "            'Probe': 2,\n",
    "            'R2L': 3,\n",
    "            'U2R': 4\n",
    "        }\n",
    "        train_data['label'] = train_data['attack_type'].map(attack_map)\n",
    "        test_data['label'] = test_data['attack_type'].map(attack_map)\n",
    "    elif classification_type == '23class':\n",
    "        # Full attack type classification\n",
    "        le = LabelEncoder()\n",
    "        train_data['label'] = le.fit_transform(train_data['attack_type'])\n",
    "        test_data['label'] = le.transform(test_data['attack_type'])\n",
    "    \n",
    "    # Select features and labels\n",
    "    X_train = train_data.drop(['attack_type', 'label', 'difficulty_level'], axis=1)\n",
    "    y_train = train_data['label']\n",
    "    X_test = test_data.drop(['attack_type', 'label', 'difficulty_level'], axis=1)\n",
    "    y_test = test_data['label']\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Model Training and Evaluation Function\n",
    "def train_and_evaluate_models(X_train, X_test, y_train, y_test, classification_type):\n",
    "    # Initialize models\n",
    "    models = {\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        'SVM': SVC(kernel='rbf', probability=True),\n",
    "        'Neural Network': MLPClassifier(max_iter=1000)\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Evaluation metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        class_report = classification_report(y_test, y_pred)\n",
    "        \n",
    "        results[name] = {\n",
    "            'Accuracy': accuracy,\n",
    "            'Confusion Matrix': conf_matrix,\n",
    "            'Classification Report': class_report\n",
    "        }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Main Execution\n",
    "def main():\n",
    "    # Load Data\n",
    "    train_data, test_data = load_nsl_kdd_data()\n",
    "    \n",
    "    # Classification Scenarios\n",
    "    classification_types = ['binary', '5class', '23class']\n",
    "    \n",
    "    for classification_type in classification_types:\n",
    "        print(f\"\\n--- {classification_type.upper()} Classification Scenario ---\")\n",
    "        \n",
    "        # Preprocess Data\n",
    "        X_train, X_test, y_train, y_test = preprocess_data(\n",
    "            train_data, test_data, classification_type\n",
    "        )\n",
    "        \n",
    "        # Train and Evaluate Models\n",
    "        results = train_and_evaluate_models(\n",
    "            X_train, X_test, y_train, y_test, classification_type\n",
    "        )\n",
    "        \n",
    "        # Visualize Results\n",
    "        for model_name, model_results in results.items():\n",
    "            print(f\"\\nModel: {model_name}\")\n",
    "            print(f\"Accuracy: {model_results['Accuracy']}\")\n",
    "            print(\"Classification Report:\\n\", model_results['Classification Report'])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics and Approaches\n",
    "\n",
    "### Performance Metrics\n",
    "1. Accuracy: Overall correct predictions\n",
    "2. Confusion Matrix: Detailed breakdown of predictions\n",
    "3. Precision, Recall, F1-Score for each class\n",
    "\n",
    "### Cross-Validation\n",
    "- Implemented using separate training and test sets\n",
    "- Utilized n-fold cross-validation techniques\n",
    "\n",
    "### Model Selection\n",
    "1. Random Forest Classifier\n",
    "2. Support Vector Machine (SVM)\n",
    "3. Multi-Layer Perceptron Neural Network\n",
    "\n",
    "### Key Considerations\n",
    "- Separate training and test data collected in different environments\n",
    "- Preprocessing includes feature scaling and encoding\n",
    "- Multiple classification scenarios implemented"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
